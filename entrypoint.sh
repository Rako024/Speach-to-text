#!/usr/bin/env bash
set -e

echo "ğŸš€ Container baÅŸlayÄ±r..."

# GPU vÉ™ CUDA yoxlamalarÄ±
echo "ğŸ”§ GPU Status:"
nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits || echo "âŒ nvidia-smi É™lÃ§atmazdÄ±r"

echo "ğŸ” CUDA Libraries:"
echo "LD_LIBRARY_PATH: $LD_LIBRARY_PATH"
ls -la /usr/lib/x86_64-linux-gnu/ | grep cudnn | head -5 || echo "âŒ cuDNN tapÄ±lmadÄ±"

echo "ğŸ Python CUDA Test:"
python -c "
import torch
print(f'âœ… PyTorch CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'âœ… CUDA device count: {torch.cuda.device_count()}')
    print(f'âœ… Current device: {torch.cuda.current_device()}')
    print(f'âœ… Device name: {torch.cuda.get_device_name(0)}')
else:
    print('âŒ CUDA not available')
"

echo "ğŸ™ï¸ Faster-Whisper Test:"
python -c "
try:
    from faster_whisper import WhisperModel
    print('âœ… faster-whisper import uÄŸurludur')
    print('âœ… faster-whisper iÅŸlÉ™yir')
except Exception as e:
    print(f'âŒ faster-whisper xÉ™tasÄ±: {e}')
"

# ğŸ¯ HÉ™m main.py, hÉ™m dÉ™ FastAPI serveri baÅŸlat
echo "ğŸ” Dispatcher (main.py) vÉ™ FastAPI (api.py) baÅŸlayÄ±r..."

# main.py fon proses kimi
python3 main.py &

# api.py foreground-da
exec uvicorn api:app --host 0.0.0.0 --port 8000 --workers 1
